{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:py3-TF2.0]",
      "language": "python",
      "name": "conda-env-py3-TF2.0-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "DeepLearning_MNIST_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa99531020d6429c8b8cd0e36aa219eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7a029bd6d94946f5a4218fe609aff95c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e3850611cf2648b1a5afc499cb337351",
              "IPY_MODEL_83e6577b303e4eb3a1c4cc631bf702db",
              "IPY_MODEL_27ec02d4e0c547cfb693d8377d352642"
            ]
          }
        },
        "7a029bd6d94946f5a4218fe609aff95c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3850611cf2648b1a5afc499cb337351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1355c44c729f43e2919aa3e1071d728f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Dl Completed...: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88c76d27c5494a278ec4b6347e387fb7"
          }
        },
        "83e6577b303e4eb3a1c4cc631bf702db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e45aa906a6ef41c6848b071664f0bae1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78b8fc2b291a466d94565b412313b8e5"
          }
        },
        "27ec02d4e0c547cfb693d8377d352642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5be34f97d5854cf38bf425580977042d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:00&lt;00:00, 12.59 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48c8b0a8e1e4447da47d4aef8cc14b7f"
          }
        },
        "1355c44c729f43e2919aa3e1071d728f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88c76d27c5494a278ec4b6347e387fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e45aa906a6ef41c6848b071664f0bae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78b8fc2b291a466d94565b412313b8e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5be34f97d5854cf38bf425580977042d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48c8b0a8e1e4447da47d4aef8cc14b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zkij2WzQ7ec"
      },
      "source": [
        "# Deep Neural Network for MNIST Classification\n",
        "\n",
        "The problem we've chosen is referred to as the \"Hello World\" of deep learning because for most students it is the first deep learning algorithm they see.\n",
        "\n",
        "The dataset is called MNIST and refers to handwritten digit recognition. You can find more about it on Yann LeCun's website (Director of AI Research, Facebook). He is one of the pioneers of what we've been talking about and of more complex approaches that are widely used today, such as covolutional neural networks (CNNs). \n",
        "\n",
        "The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image). \n",
        "\n",
        "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes. \n",
        "\n",
        "Our goal would be to build a neural network with 2 hidden layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrvseCT7Q7eh"
      },
      "source": [
        "## Import the relevant packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j81vjrDCQ7ei"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# TensorFLow includes a data provider for MNIST that we'll use.\n",
        "# It comes with the tensorflow-datasets module.\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# these datasets will be stored in C:\\Users\\*USERNAME*\\tensorflow_datasets\\...\n",
        "# the first time you download a dataset, it is stored in the respective folder \n",
        "# every other time, it is automatically loading the copy on your computer "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMReE7BRQ7ej"
      },
      "source": [
        "## Data\n",
        "\n",
        "Here, we load and preprocess our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "aa99531020d6429c8b8cd0e36aa219eb",
            "7a029bd6d94946f5a4218fe609aff95c",
            "e3850611cf2648b1a5afc499cb337351",
            "83e6577b303e4eb3a1c4cc631bf702db",
            "27ec02d4e0c547cfb693d8377d352642",
            "1355c44c729f43e2919aa3e1071d728f",
            "88c76d27c5494a278ec4b6347e387fb7",
            "e45aa906a6ef41c6848b071664f0bae1",
            "78b8fc2b291a466d94565b412313b8e5",
            "5be34f97d5854cf38bf425580977042d",
            "48c8b0a8e1e4447da47d4aef8cc14b7f"
          ]
        },
        "id": "PeqLXJD0bMI-",
        "outputId": "5174e893-cdb0-4245-82ae-18363d6be6a3"
      },
      "source": [
        "# tfds.load loads a dataset (or downloads and then loads if that's the first time you use it) \n",
        "# in our case, we are interesteed in the MNIST; the name of the dataset is the only mandatory argument\n",
        "# there are other arguments we can specify.\n",
        "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "\n",
        "# with_info=True will also provide us with a tuple containing information about the version, features, number of samples\n",
        "# we will use this information a bit below and we will store it in mnist_info\n",
        "\n",
        "# as_supervised=True will load the dataset in a 2-tuple structure (input, target) \n",
        "# alternatively, as_supervised=False, would return a dictionary"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa99531020d6429c8b8cd0e36aa219eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7xd3VcUd9cJ"
      },
      "source": [
        "we prefer to have our inputs and targets separated.\n",
        "Once we have loaded the dataset, we can easily extract the training and testing dataset with the built references"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaO4puwPbS4o"
      },
      "source": [
        "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYONhlz8eHCA"
      },
      "source": [
        "By default, TF has training and testing datasets, but no validation sets splitting of validation set will be taken care by us"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz-VkJeqbW2S"
      },
      "source": [
        "# we start by defining the number of validation samples as a % of the train samples\n",
        "# we can make use of mnist_info for getting the numbers\n",
        "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
        "# number is cast to an integer, as a float may cause an error along the way\n",
        "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
        "\n",
        "# the number of test samples is stored in a dedicated variable\n",
        "num_test_samples = mnist_info.splits['test'].num_examples\n",
        "# number is cast to an integer\n",
        "num_test_samples = tf.cast(num_test_samples, tf.int64)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAemRGdGeQa3"
      },
      "source": [
        "Normally, we would like to scale our data in some way to make the result more numerically stable. In this case we prefer to have inputs between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46cxWHDEbfQT"
      },
      "source": [
        "# a function called: scale is defined that will take an MNIST image and its label\n",
        "def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    # since the possible values for the inputs are 0 to 255 (256 different shades of grey)\n",
        "    # each element is divided by 255\n",
        "    image /= 255.\n",
        "\n",
        "    return image, label\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJRyem82bnlz"
      },
      "source": [
        "# the method .map() allows us to apply a custom transformation to a given dataset \n",
        "scaled_train_and_validation_data = mnist_train.map(scale)\n",
        "\n",
        "# finally, we scale and batch the test data\n",
        "# we scale it so it has the same magnitude as the train and validation\n",
        "# there is no need to shuffle it\n",
        "# there would be a single batch, equal to the size of the test data\n",
        "test_data = mnist_test.map(scale)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afcxDp1VebPP"
      },
      "source": [
        "Shuffle the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SNgStP0b2sh"
      },
      "source": [
        "\n",
        "BUFFER_SIZE = 10000\n",
        "# this BUFFER_SIZE parameter is here for cases when we're dealing with enormous datasets\n",
        "# then we can't shuffle the whole dataset in one go because we can't fit it all in memory\n",
        "# so instead TF only stores BUFFER_SIZE samples in memory at a time and shuffles them\n",
        "# if BUFFER_SIZE=1 => no shuffling will actually happen\n",
        "# if BUFFER_SIZE >= num samples => shuffling is uniform\n",
        "# BUFFER_SIZE in between - a computational optimization to approximate uniform shuffling\n",
        "\n",
        "# shuffling the dataset\n",
        "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEWtGbM5efv8"
      },
      "source": [
        "once we have scaled and shuffled the data, we can proceed to actually extracting the train and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZajFI-eYcFd_"
      },
      "source": [
        "\n",
        "# our validation data would be equal to 10% of the training set, which we've already calculated\n",
        "# we use the .take() method to take that many samples\n",
        "# finally, we create a batch with a batch size equal to the total number of validation samples\n",
        "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
        "\n",
        "# similarly, the train_data is everything else, so we skip as many samples as there are in the validation dataset\n",
        "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIjwknpSQ7ek"
      },
      "source": [
        "# determine the batch size\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# we can also take advantage of the occasion to batch the train data\n",
        "# this would be very helpful when we train, as we would be able to iterate over the different batches\n",
        "train_data = train_data.batch(BATCH_SIZE)\n",
        "\n",
        "#no need to convert the validation data to batches, but the model expects it in batches.\n",
        "#so converting the data to batch of the same size\n",
        "validation_data = validation_data.batch(num_validation_samples)\n",
        "\n",
        "# batch the test data\n",
        "test_data = test_data.batch(num_test_samples)\n",
        "\n",
        "\n",
        "# takes next batch (it is the only batch)\n",
        "# because as_supervized=True, we've got a 2-tuple structure\n",
        "validation_inputs, validation_targets = next(iter(validation_data))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohWkRxuwQ7ep"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAfpS35PQ7eq"
      },
      "source": [
        "### Outline the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xysSnmyyQ7er"
      },
      "source": [
        "input_size = 784\n",
        "output_size = 10\n",
        "# We use same size for both hidden layers\n",
        "hidden_layer_size = 50\n",
        "    \n",
        "# define the model\n",
        "model = tf.keras.Sequential([\n",
        "    \n",
        "    # the first layer (the input layer)\n",
        "    # each observation is 28x28x1 pixels, therefore it is a tensor of rank 3\n",
        "    # we must flatten the images since we are not using CNN\n",
        "    # there is a convenient method 'Flatten' that simply takes our 28x28x1 tensor and orders it into a (None,) \n",
        "    # or (28x28x1,) = (784,) vector\n",
        "    # this allows us to create a feed forward neural network\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # input layer\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer \n",
        "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer. \n",
        "    #The Activation function used is 'softmax' since we are dealing with classification\n",
        "])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkY6TFceQ7es"
      },
      "source": [
        "### Choose the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUYLIa_0Q7et"
      },
      "source": [
        "# we define the optimizer we'd like to use, \n",
        "# the loss function, \n",
        "# and the metrics we are interested in obtaining at each iteration\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJoK8cKOQ7eu"
      },
      "source": [
        "### Training\n",
        "That's where we train the model we have built."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQCWv0YMQ7eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "860e063c-862f-4719-931b-1f02e4b44c96"
      },
      "source": [
        "# determine the maximum number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# we fit the model, specifying the training data, the total number of epochs and the validation data\n",
        "model.fit(train_data, epochs=NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose =2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "540/540 - 10s - loss: 0.4212 - accuracy: 0.8804 - val_loss: 0.2068 - val_accuracy: 0.9400\n",
            "Epoch 2/5\n",
            "540/540 - 4s - loss: 0.1826 - accuracy: 0.9472 - val_loss: 0.1697 - val_accuracy: 0.9492\n",
            "Epoch 3/5\n",
            "540/540 - 4s - loss: 0.1374 - accuracy: 0.9598 - val_loss: 0.1274 - val_accuracy: 0.9642\n",
            "Epoch 4/5\n",
            "540/540 - 4s - loss: 0.1118 - accuracy: 0.9661 - val_loss: 0.1071 - val_accuracy: 0.9680\n",
            "Epoch 5/5\n",
            "540/540 - 4s - loss: 0.0946 - accuracy: 0.9720 - val_loss: 0.1018 - val_accuracy: 0.9688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd1c3c9550>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuUl4CxKQ7ev"
      },
      "source": [
        "## Test the model\n",
        "\n",
        "After training on the training data and validating on the validation data, we test the final prediction power of our model by running it on the test dataset that the algorithm has never seen before.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUbVnHJjQ7ew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928d2d60-0539-4bf4-e634-3f15d91cfea8"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 0.1131 - accuracy: 0.9663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpP91TEEQ7ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6dc3c2-ed37-49de-b513-f523ac8ed11f"
      },
      "source": [
        "#Test loss and Test accuracy are printed\n",
        "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.11. Test accuracy: 96.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjFrHkAkQ7ey"
      },
      "source": [
        "Using the initial model and hyperparameters given in this notebook, the final test accuracy should be roughly around 96%.\n",
        "\n",
        "Each time the code is rerun, we get a different accuracy as the batches are shuffled, the weights are initialized in a different way, etc.\n",
        "\n",
        "Finally, we have intentionally reached a suboptimal solution."
      ]
    }
  ]
}